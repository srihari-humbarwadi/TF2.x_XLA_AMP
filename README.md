# TF2.x XLA AMP
Training with XLA compilation and Mixed Precision with TF2.x

#### Get 3.4+ times speed up on double the batch size with almost no change in code!

![](results.png)

##### PS: 
 - Maximum possible batch sizes on both FP32 and FP16 (128 and 256)
 - Results on V100 16GB
 
#### ToDo
- [ ] Distributed Single Worker
- [ ] Distributed Multi Worker
